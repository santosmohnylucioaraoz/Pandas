# BIG DATA y DATOS EN PEQUEÑA ESCALA

### Diferencias entre Big Data y Datos en Pequeña Escala
## Tamaño del Dataset:

#### Datos en Pequeña Escala: 
- Tienen un tamaño que cabe en la memoria RAM de una sola máquina. Generalmente, esto es desde unos pocos megabytes (MB) hasta algunos gigabytes (GB).
#### Big Data: 
- Supera la capacidad de almacenamiento y procesamiento de una sola máquina. Generalmente involucra terabytes (TB) o petabytes (PB) de datos.

## Capacidad de Procesamiento:

#### Datos en Pequeña Escala: 
- Se pueden procesar y analizar con herramientas estándar como Pandas en Python o Excel en una sola computadora.
#### Big Data: 
- Requiere tecnologías especializadas para procesamiento distribuido, como Hadoop o Apache Spark, y a menudo involucra clústeres de servidores o soluciones en la nube.

## Velocidad de Generación:

#### Datos en Pequeña Escala: 
- La tasa de generación de datos es baja o moderada, y el procesamiento puede realizarse en tiempo no real.
#### Big Data: 
- Los datos se generan a alta velocidad y requieren procesamiento en tiempo real o casi en tiempo real.

## Complejidad de Datos:

#### Datos en Pequeña Escala: 
- Los datos suelen tener una estructura simple y fácil de manejar, como tablas con un número limitado de filas y columnas.
#### Big Data: 
- Los datos pueden ser complejos y variados, incluyendo datos no estructurados (imágenes, textos, videos) y estructuras de datos con alta dimensionalidad.

## Requerimientos de Infraestructura:

#### Datos en Pequeña Escala: 
- Puede utilizar almacenamiento local y computación en una sola máquina o en una red pequeña.
#### Big Data: 
- Necesita infraestructura distribuida para almacenamiento y procesamiento, como sistemas de archivos distribuidos y plataformas en la nube.

## Ejemplos
#### Datos en Pequeña Escala: 
- Un archivo CSV de 100,000 filas que se puede analizar en una laptop.
#### Big Data: 
-  Un dataset de 100 TB de registros de transacciones que se procesa en un clúster de servidores utilizando Apache Spark.
